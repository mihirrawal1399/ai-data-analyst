# Database Configuration
DATABASE_URL="postgresql://user:password@localhost:5432/ai_data_analyst?schema=public"

# API Configuration
API_PORT=4000
NODE_ENV=development

# ============================================
# LLM Configuration - System Keys (Default)
# ============================================
LLM_PROVIDER=openai  # Options: openai, anthropic, google, groq, ollama
LLM_MODEL=gpt-4o-mini  # Provider-specific model name

# System API Keys (for guest/free/premium users)
# You can provide multiple keys for load balancing (comma-separated)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=...
GROQ_API_KEY=gsk_...

# Ollama Configuration (free, local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# LLM Settings
LLM_MAX_TOKENS=2000
LLM_TEMPERATURE=0.1  # Lower = more deterministic SQL

# ============================================
# Query Limits & Quotas
# ============================================
QUERY_RESULT_LIMIT=100
QUERY_TIMEOUT_MS=30000

# Guest User Limits (not enforced yet, but planned)
GUEST_DAILY_QUERY_LIMIT=5
GUEST_ALLOWED_PROVIDERS=ollama,google

# Free Tier Limits (not enforced yet, but planned)
FREE_MONTHLY_QUERY_LIMIT=50
FREE_ALLOWED_PROVIDERS=openai,google,groq

# Premium Tier Limits (not enforced yet, but planned)
PREMIUM_MONTHLY_QUERY_LIMIT=500
PREMIUM_ALLOWED_PROVIDERS=openai,anthropic,google,groq

# Enterprise/SaaS (not enforced yet, but planned)
ENTERPRISE_MONTHLY_QUERY_LIMIT=10000
ENTERPRISE_ALLOWED_PROVIDERS=all

# ============================================
# BYOK (Bring Your Own Key) Settings
# ============================================
BYOK_ENABLED=true
BYOK_ALLOWED_PROVIDERS=openai,anthropic,google,groq

# Note: Copy this file to .env and update with your actual values
# Never commit .env file to version control
